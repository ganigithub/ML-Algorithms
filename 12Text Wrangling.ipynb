{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ccb55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical\n",
    "#natural language processing (NLP) for English written in the Python programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd78f37",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ganesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ganesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ganesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ganesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b3798",
   "metadata": {},
   "source": [
    "### Case conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef1ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ML can help in converting text to numeric feature vectors.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b19263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ml can help in converting text to numeric feature vectors.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lower()  #all lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1fb60ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ML CAN HELP IN CONVERTING TEXT TO NUMERIC FEATURE VECTORS.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.upper()  #all upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd18e2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ml Can Help In Converting Text To Numeric Feature Vectors.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.title()  #starting of each word capital"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c9327",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee683473",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Text preprocessing is crucial step in NLP. Cleaning our text data in order to convert it into presentable form that is analyzable and predictable for our task is known as text preprocessing.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13153bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text preprocessing is crucial step in NLP.',\n",
       " 'Cleaning our text data in order to convert it into presentable form that is analyzable and predictable for our task is known as text preprocessing.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text) #divides text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0310c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Text', 'preprocessing', 'is', 'crucial', 'step', 'in', 'NLP', '.', 'Cleaning', 'our', 'text', 'data', 'in', 'order', 'to', 'convert', 'it', 'into', 'presentable', 'form', 'that', 'is', 'analyzable', 'and', 'predictable', 'for', 'our', 'task', 'is', 'known', 'as', 'text', 'preprocessing', '.']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.word_tokenize(text))  #makes a list of each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c96b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a27e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0284a83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('leav', 'leav', 'left', 'lie')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "ps.stem('leaving'), ps.stem('leaves'), ps.stem('left'), ps.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b334333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3981e8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'hello'\n",
    "a.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5a39bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e551b3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2896e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fae4a639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hiii.', 'How are you.', 'I am good.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize('hiii. How are you. I am good.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0494a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
